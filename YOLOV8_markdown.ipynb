{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d83DC6pklcuR"
      },
      "source": [
        "The whole code was run on rstudio, and later that markdown file converted into the notebook, so here it is the notebook version of the code which was executed for extracting the results. So, in this notebook the outputs are not visible, but the markdown file also shared please refer to it.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xoOwxjGElcuU"
      },
      "outputs": [],
      "source": [
        "knitr::opts_chunk$set(echo = TRUE)\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c-C1sASLlcuW"
      },
      "source": [
        "## R Markdown\n",
        "\n",
        "This is an R Markdown document. Markdown is a simple formatting syntax for authoring HTML, PDF, and MS Word documents. For more details on using R Markdown see <http://rmarkdown.rstudio.com>.\n",
        "\n",
        "When you click the **Knit** button a document will be generated that includes both content as well as the output of any embedded R code chunks within the document. You can embed an R code chunk like this:\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "f8tlw7KzlcuX"
      },
      "outputs": [],
      "source": [
        "# Set the working directory to a specific path\n",
        "setwd(\"D:/NICMAR Project/DSPS24\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fuH28iKllcuX"
      },
      "source": [
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9DqXz-BslcuY"
      },
      "outputs": [],
      "source": [
        "from ultralytics import YOLO"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Rp1ynxHFlcuY"
      },
      "source": [
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ahOhemmllcuY"
      },
      "outputs": [],
      "source": [
        "import os,shutil\n",
        "import torch\n",
        "import pandas as pd\n",
        "from skimage import io, transform\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from torchvision import transforms, utils\n",
        "from pathlib import Path\n",
        "from PIL import Image\n",
        "# Ignore warnings\n",
        "import warnings\n",
        "from tqdm import tqdm\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "\n",
        "plt.ion()   # interactive mode\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o2ZZbpH9lcuZ"
      },
      "source": [
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DNFKIRJPlcuZ"
      },
      "outputs": [],
      "source": [
        "class pavement_data(Dataset):\n",
        "    def __init__(self, root_dir, csv_path):\n",
        "        self.root = Path(root_dir)\n",
        "\n",
        "        self.df = pd.read_csv(os.path.join(root_dir,csv_path))\n",
        "        self.df = self.df.sample(frac=1)\n",
        "        self.image_names = [os.path.join(self.root,'train',i) for i in self.df['image_name'].values]\n",
        "        self.pci_label = list(self.df['pci'].values)\n",
        "\n",
        "    def __len__(self):\n",
        "        # returns the length of the dataset\n",
        "        return len(self.image_names)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "\n",
        "    #     # preprocess and transformations\n",
        "    #     # indexes the dataset such that dataset[i] can retrieve the ith sample.\n",
        "        image = self.image_names[idx]\n",
        "        # print (image)\n",
        "        if os.path.isfile(image):\n",
        "            image_data = io.imread(image)\n",
        "            # print (image_data)\n",
        "\n",
        "            label = self.pci_label[idx]\n",
        "\n",
        "            sample = {'image': image_data, 'image_path':image,'label': label}\n",
        "\n",
        "            return sample\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cGlQeQvHlcuZ"
      },
      "source": [
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "G_hsDjU5lcuZ"
      },
      "outputs": [],
      "source": [
        "pavement_dataset = pavement_data('D:/NICMAR Project/DSPS24','train.csv')\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "il2kT1Hklcua"
      },
      "source": [
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GLNXQDmulcua"
      },
      "outputs": [],
      "source": [
        "for idx, sample in enumerate(pavement_dataset):\n",
        "    print (sample['image'].shape, sample['label'])\n",
        "\n",
        "    if idx == 5:\n",
        "        break\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y8c5xm79lcua"
      },
      "source": [
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vxMjESeUlcua"
      },
      "outputs": [],
      "source": [
        "class prep_data(object):\n",
        "  def __init__(self,root_dir,csv_path):\n",
        "    self.root = Path(root_dir)\n",
        "    self.df = pd.read_csv(os.path.join(root_dir,csv_path))\n",
        "    self.image_names = [os.path.join(self.root,'train',i) for i in self.df['image_name'].values]\n",
        "    self.pci_label = list(self.df['pci'].values)\n",
        "    self.train_folder = os.path.join(root_dir,'yolov8','train')\n",
        "    self.val_folder = os.path.join(root_dir,'yolov8','val')\n",
        "    Path(self.train_folder).mkdir(parents=True, exist_ok=True)\n",
        "    Path(self.val_folder).mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "  def __call__(self,sample):\n",
        "    if not sample is None:\n",
        "      image, img_path, labels = sample['image'],sample['image_path'], sample['label']\n",
        "      # print (img_path)\n",
        "      # print (labels)\n",
        "      dst_folder = os.path.join(self.train_folder,str(labels))\n",
        "      Path(dst_folder).mkdir(parents=True, exist_ok=True)\n",
        "      fname = os.path.basename(img_path)\n",
        "      if not os.path.isfile(os.path.join(dst_folder,fname)):\n",
        "        shutil.copy2(img_path,dst_folder)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FgCHF2U8lcua"
      },
      "source": [
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "V2Tr40pBlcua"
      },
      "outputs": [],
      "source": [
        "obj_prep = prep_data('D:/NICMAR Project/DSPS24','train.csv')\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M9geE6pWlcua"
      },
      "source": [
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YbtrVTgKlcub"
      },
      "outputs": [],
      "source": [
        "import random\n",
        "\n",
        "class prep_data(object):\n",
        "    def __init__(self, root_dir, csv_path):\n",
        "        self.root = Path(root_dir)\n",
        "        self.df = pd.read_csv(os.path.join(root_dir, csv_path))\n",
        "        self.image_names = [os.path.join(self.root, 'train', i) for i in self.df['image_name'].values]\n",
        "        self.pci_label = list(self.df['pci'].values)\n",
        "        self.train_folder = os.path.join(root_dir, 'yolov8', 'train')\n",
        "        self.val_folder = os.path.join(root_dir, 'yolov8', 'val')\n",
        "        Path(self.train_folder).mkdir(parents=True, exist_ok=True)\n",
        "        Path(self.val_folder).mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "    def __call__(self, sample):\n",
        "        if not sample is None:\n",
        "            image, img_path, labels = sample['image'], sample['image_path'], sample['label']\n",
        "\n",
        "            # Determine the destination folder\n",
        "            if random.random() < 0.2:  # 20% chance for validation\n",
        "                dst_folder = os.path.join(self.val_folder, str(labels))\n",
        "            else:\n",
        "                dst_folder = os.path.join(self.train_folder, str(labels))\n",
        "\n",
        "            Path(dst_folder).mkdir(parents=True, exist_ok=True)\n",
        "            fname = os.path.basename(img_path)\n",
        "            if not os.path.isfile(os.path.join(dst_folder, fname)):\n",
        "                shutil.copy2(img_path, dst_folder)\n",
        "\n",
        "# Create an instance of prep_data\n",
        "obj_prep = prep_data('D:/NICMAR Project/DSPS24','train.csv')\n",
        "\n",
        "# Assuming pavement_dataset contains all the samples\n",
        "for sample in tqdm(pavement_dataset):\n",
        "    obj_prep(sample)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xRw7kQLvlcub"
      },
      "source": [
        "By using the above code, yolov8 folder created which constitutes of train and val folder which consists of different classes.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Za77JaSBlcub"
      },
      "outputs": [],
      "source": [
        "install.packages(\"tensorflow\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-Gix6v1zlcub"
      },
      "source": [
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yjrShv8Klcub"
      },
      "outputs": [],
      "source": [
        "library(tensorflow)\n",
        "# Enable GPU if available\n",
        "tf$device('/device:GPU:0')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZrDfBQ1Plcub"
      },
      "source": [
        "First the model was trained using yolov8n-cls model, which gives the MAPE around 45.867. Submission.json file was obtained using this model, which is in the repository.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DfjPuRAolcub"
      },
      "outputs": [],
      "source": [
        "model = YOLO('yolov8n-cls.pt')\n",
        "# model = YOLO('runs/classify/train3/weights/last.pt')\n",
        "# model.train(data='dsps/yolov8', epochs=100)\n",
        "\n",
        "model.train(data=\"D:/NICMAR Project/DSPS24/yolov8\",epochs=100)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fwGMVCI6lcub"
      },
      "source": [
        "Secondly the previously obtained weights was again trained with almost 60 epochs, then again this weights were used but MAPE value was obtained higher than this and the trained weights are saved in train11 folder. It's results are saved as submission_12_modified.json.\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iWcTut9Ulcub"
      },
      "outputs": [],
      "source": [
        "model = YOLO(\"D:/NICMAR Project/DSPS24/runs/classify/train4/weights/last.pt\")\n",
        "# model = YOLO('runs/classify/train3/weights/last.pt')\n",
        "# model.train(data='dsps/yolov8', epochs=100)\n",
        "\n",
        "model.train(data=\"D:/NICMAR Project/DSPS24/yolov8\",epochs=100)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NVOiunftlcuc"
      },
      "source": [
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oW4Bem79lcuc"
      },
      "outputs": [],
      "source": [
        "model = YOLO(\"D:/NICMAR Project/DSPS24/runs/classify/train4/weights/last.pt\")\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vRwVxxHFlcuc"
      },
      "source": [
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "atXKY82Hlcuc"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "test_path = Path(\"D:/NICMAR Project/DSPS24/test\")\n",
        "rows = []\n",
        "for tst_img in test_path.glob('**/*.jpg'):\n",
        "    preds = model(tst_img)\n",
        "    cls_dict = preds[0].names\n",
        "    probs = preds[0].probs.data.cpu().numpy()\n",
        "    rows.append({'image_name':os.path.basename(tst_img),\n",
        "                 'pci':cls_dict[np.argmax(probs)]})\n",
        "df_test = pd.DataFrame(rows)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gX1pp_eflcuc"
      },
      "source": [
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "# df: should have two columns - image_name and PCI\n",
        "def gen_submit(df):\n",
        "  out_json = []\n",
        "  for idx, results in df.iterrows():\n",
        "    out_json.append({results['image_name']:results['pci']})\n",
        "  with open('D:/NICMAR Project/DSPS24/submission.json', 'w') as f:\n",
        "    json.dump(out_json, f)\n",
        "df_test['pci'] = df_test['pci'].astype(int)\n",
        "gen_submit(df_test)"
      ],
      "metadata": {
        "id": "lkrCe610nD9B"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5LC-64H7lcuc"
      },
      "outputs": [],
      "source": [
        "model_1 = YOLO(\"D:/NICMAR Project/DSPS24/runs/classify/train11/weights/last.pt\")\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dnfrPgCClcuc"
      },
      "source": [
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "245-IwNvlcuc"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "test_path = Path(\"D:/NICMAR Project/DSPS24/test\")\n",
        "rows = []\n",
        "for tst_img in test_path.glob('**/*.jpg'):\n",
        "    preds = model_1(tst_img)\n",
        "    cls_dict = preds[0].names\n",
        "    probs = preds[0].probs.data.cpu().numpy()\n",
        "    rows.append({'image_name':os.path.basename(tst_img),\n",
        "                 'pci':cls_dict[np.argmax(probs)]})\n",
        "\n",
        "df_test_1 = pd.DataFrame(rows)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ODUU5O4Slcud"
      },
      "source": [
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aKG2AJeflcud"
      },
      "outputs": [],
      "source": [
        "import json\n",
        "# df: should have two columns - image_name and PCI\n",
        "def gen_submit(df):\n",
        "  out_json = []\n",
        "  for idx, results in df.iterrows():\n",
        "    out_json.append({results['image_name']:results['pci']})\n",
        "  with open('D:/NICMAR Project/DSPS24/submission_12_modified.json', 'w') as f:\n",
        "    json.dump(out_json, f)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LmY8H9lslcud"
      },
      "source": [
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bcOI943elcuh"
      },
      "outputs": [],
      "source": [
        "df_test_1['pci'] = df_test_1['pci'].astype(int)\n",
        "gen_submit(df_test_1)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZykPIub2lcuh"
      },
      "source": [
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Dn559PBilcuh"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zbIp8w-Elcuh"
      },
      "source": [
        "\n",
        "\n"
      ]
    }
  ],
  "metadata": {
    "anaconda-cloud": "",
    "kernelspec": {
      "display_name": "R",
      "langauge": "R",
      "name": "ir"
    },
    "language_info": {
      "codemirror_mode": "r",
      "file_extension": ".r",
      "mimetype": "text/x-r-source",
      "name": "R",
      "pygments_lexer": "r",
      "version": "3.4.1"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}